{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EdLXs7-aIlv"
   },
   "source": [
    "# TEAM 5 - Software Design 1 | Model Training\n",
    "This notebook is to demonstrate the models used in our software design about water quality classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9p5Vm6ueMpV"
   },
   "source": [
    "# Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6NOmVE-eRtY",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVfbmKcseV3o"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,r2_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "import os\n",
    "import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFEMWG4grRfe",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Import dataset\n",
    "[Dataset](https://figshare.com/articles/dataset/A_Comprehensive_Surface_Water_Quality_Monitoring_Dataset_1940-2023_2_82Million_Record_Resource_for_Empirical_and_ML-Based_Research/27800394/2?file=50757303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 956
    },
    "id": "qRgrmxBjq--R",
    "outputId": "38da375f-f53f-4112-e809-393dc315390e"
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/Leon/Documents/Jupyter/softdes/27800394/Dataset/Combined Data/Combined_dataset.csv'\n",
    "water_df = pd.read_csv(path)\n",
    "water_df.tail(10) #show latest data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Standardize Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = water_df.copy()\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "\n",
    "#separate Date into Year, Month, Day columns\n",
    "# Insert after Date (at index of Date + 1, +2, +3)\n",
    "date_idx = df.columns.get_loc('Date')\n",
    "\n",
    "df.insert(date_idx + 1, 'Year', df['Date'].dt.year)\n",
    "df.insert(date_idx + 2, 'Month', df['Date'].dt.month)\n",
    "df.insert(date_idx + 3, 'Day', df['Date'].dt.day)\n",
    "\n",
    "df = df.drop(columns=['Date'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dV3DloHMreEr",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reading Dataset Dimensions and Feature Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQoznqPiCcpc",
    "outputId": "6fbeaebf-d8b1-45ef-956a-4764ec378ff5"
   },
   "outputs": [],
   "source": [
    "print(\"Number of datapoints (rows):\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])\n",
    "print(\"\\nData types:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CCME_WQI'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Waterbody Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freshwater body types: 'River','Effluent','Sewage','Lake','Canal','Drainage' <br>\n",
    "Saltwater body types: 'Bay','Sea Water','Marine','Coastal' <br>\n",
    "Neither: 'Transitional','Estuarine' <br>\n",
    "\n",
    "We'll only take the freshwater body types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_counts = df.groupby('Year').size().reset_index(name='Count')\n",
    "year_counts.tail(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take the data points gathered since the start of the 2000s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Remove unnecessary rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out records of non-freshwater bodies of water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freshwater_types = ['River', 'Effluent', 'Sewage', 'Lake', 'Canal', 'Drainage']\n",
    "df_fresh = df[df['Waterbody Type'].isin(freshwater_types)]\n",
    "df_fresh['Waterbody Type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of datapoints (rows):\", df_fresh.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only get the records starting from 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fresh_2000 = df_fresh[df_fresh['Year'] >= 2000]\n",
    "print(\"Number of datapoints (rows):\", df_fresh_2000.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxN9YGNKCsif",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Check for empty or missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJOyURsMCr-z",
    "outputId": "b7c86243-88a5-44d1-a6bb-723ffe561b88"
   },
   "outputs": [],
   "source": [
    "print(\"\\nMissing values per column:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().applymap(lambda x: f\"{x:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Managing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df_filtered['Ammonia (mg/l)'].quantile(0.25)\n",
    "Q3 = df_filtered['Ammonia (mg/l)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1 * IQR\n",
    "upper_bound = Q3 + 1 * IQR   \n",
    "df_filtered = df_filtered[(df_filtered['Ammonia (mg/l)'] >= lower_bound) & (df_filtered['Ammonia (mg/l)'] <= upper_bound)]\n",
    "df_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df_filtered['pH (ph units)'].quantile(0.25)\n",
    "Q3 = df_filtered['pH (ph units)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1 * IQR\n",
    "upper_bound = Q3 + 1 * IQR   \n",
    "df_filtered = df_filtered[(df_filtered['pH (ph units)'] >= lower_bound) & (df_filtered['pH (ph units)'] <= upper_bound)]\n",
    "df_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df_filtered['Nitrate (mg/l)'].quantile(0.25)\n",
    "Q3 = df_filtered['Nitrate (mg/l)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1 * IQR\n",
    "upper_bound = Q3 + 1 * IQR   \n",
    "df_filtered = df_filtered[(df_filtered['Nitrate (mg/l)'] >= lower_bound) & (df_filtered['Nitrate (mg/l)'] <= upper_bound)]\n",
    "df_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['CCME_WQI'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s39-WJfaj7Pb",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Label Encoding of Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pH9VhwUTkiTN",
    "outputId": "b82a8e83-8f0d-49f5-f72f-deed910acefa"
   },
   "outputs": [],
   "source": [
    "df_mapped = df_filtered.copy()\n",
    "\n",
    "mapping = {\n",
    "    \"Excellent\": 5,\n",
    "    \"Good\": 4,\n",
    "    \"Fair\": 3,\n",
    "    \"Marginal\": 2,\n",
    "    \"Poor\": 1\n",
    "}\n",
    "\n",
    "df_mapped[\"CCME_WQI\"] = df_mapped[\"CCME_WQI\"].map(mapping)\n",
    "df_mapped.groupby(\"CCME_WQI\").head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BYdY_awC56C",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Removal of unnecessary features/columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U52pa89BCh3k",
    "outputId": "b89d92e3-97bc-4293-ffec-e0339b7b1017"
   },
   "outputs": [],
   "source": [
    "print(list(df_final.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mcm9Nt-yD0gy"
   },
   "source": [
    "*The only columns needed are data pertaining to pH level, Nitrate concentration, and Ammonia concentration, as these are the components used in DENR water quality guidelines and standards that can also be tested by the client in remote areas through reagents for the aforementioned components.*\n",
    "\n",
    "*So, that leaves us with 4 columns (the 3 columns for the components and the water classification)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "z5Y_i1mFD0Cj",
    "outputId": "3a3c6c93-c3f1-4ef6-fb14-52dd96695503"
   },
   "outputs": [],
   "source": [
    "df_filtered = df_final[['Ammonia (mg/l)',\n",
    "                        'Biochemical Oxygen Demand (mg/l)',\n",
    "                        'Dissolved Oxygen (mg/l)',\n",
    "                        'Orthophosphate (mg/l)',\n",
    "                        'pH (ph units)',\n",
    "                        #temperature was not included \n",
    "                        'Nitrogen (mg/l)',\n",
    "                        'Nitrate (mg/l)',\n",
    "                        'CCME_Values' \n",
    "                ]]\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redo Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification that will be used is based on the [DENR Guidelines for Water Quality Management in the Philippines (DAO 2016-08)](https://emb.gov.ph/wp-content/uploads/2019/04/DAO-2016-08_WATER-QUALITY-GUIDELINES-AND-GENERAL-EFFLUENT-STANDARDS.pdf). \n",
    "For freshwater analysis, we'll be using Classes A, B, C, and D. Clustering was used to help determine if 4 classes is enough to group the data points together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering via K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df_filtered)\n",
    "\n",
    "# statistics of scaled data\n",
    "pd.DataFrame(data_scaled).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use elbow method to determine the optimal number of clusters\"\"\"\n",
    "# fitting multiple k-means algorithms and storing the values in an empty list\n",
    "SSE = []\n",
    "for cluster in range(1,20):\n",
    "    kmeans = KMeans(n_clusters = cluster, init='k-means++')\n",
    "    kmeans.fit(data_scaled)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "# converting the results into a dataframe and plotting them\n",
    "frame = pd.DataFrame({'Cluster':range(1,20), 'SSE':SSE})\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(frame['Cluster'], frame['SSE'], marker='o', linestyle='--')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster of n-clusters\n",
    "kmeans = KMeans(n_clusters=16, init='k-means++')\n",
    "\n",
    "# fit the k means algorithm on scaled data\n",
    "kmeans.fit(data_scaled)\n",
    "# inertia on the fitted data\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = kmeans.predict(data_scaled)\n",
    "frame = pd.DataFrame(data_scaled)\n",
    "frame['cluster'] = pred\n",
    "frame['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export into a Parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the resulting dataframe into a more efficient data format compared to CSV is essential to reduce the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = \"C:/Users/Leon/Documents/Github/CPE025A/df_parquet.parquet\"\n",
    "df_mapped.to_parquet(parquet_path)\n",
    "print(f\"Saved preprocessed data to {parquet_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gqkk5VTdFOqq"
   },
   "source": [
    "### Prepare for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = pd.read_parquet(parquet_path)\n",
    "df_parquet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of datapoints (rows):\", df_parquet.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_pOkMHaFOJz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = df_parquet.drop(columns=['CCME_WQI','Class'], axis=1)\n",
    "y = df_parquet['Class']\n",
    "\n",
    "# Split sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO9cwo5wPW2S"
   },
   "source": [
    "## Training of Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AUHPLSmPY6G"
   },
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uj3UcAORvJ1d"
   },
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "qxuwF7DnPWIa",
    "outputId": "752f746f-189b-4be0-fc7a-29289d26a04b"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "# Initialize Random Forest with multiple cores and 300 trees\n",
    "rf = RandomForestClassifier(n_estimators=300, \n",
    "                            random_state=42, \n",
    "                            n_jobs=-1,\n",
    "                            class_weight='balanced',\n",
    "                            min_samples_split= 5, \n",
    "                            min_samples_leaf= 10, \n",
    "                            max_depth= 5)\n",
    "\n",
    "# Measure training time\n",
    "start_time_train = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Training finished!\")\n",
    "end_time_train = time.time()\n",
    "\n",
    "train_preds = rf.predict(X_train)            # Training predictions\n",
    "start_time_predict = time.time()\n",
    "predictions = rf.predict(X_test)\n",
    "end_time_predict = time.time()\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"Random Forest Train Accuracy:\", accuracy_score(y_train, train_preds))\n",
    "print(\"Random Forest Test Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(f\"Random Forest training time: {end_time_train - start_time_train:.2f} seconds\")\n",
    "print(f\"Random Forest prediction time: {end_time_predict - start_time_predict:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# List of n_estimators to try\n",
    "n_values = range(100, 1100, 200)\n",
    "\n",
    "# Store results\n",
    "accuracies = []\n",
    "train_times = []\n",
    "predict_times = []\n",
    "\n",
    "for n in n_values:\n",
    "    # Initialize RF with n trees and all cores\n",
    "    rf = RandomForestClassifier(n_estimators=n, \n",
    "                                random_state=42, \n",
    "                                n_jobs=-1,\n",
    "                                class_weight='balanced',\n",
    "                                min_samples_split= 5, \n",
    "                                min_samples_leaf= 10, \n",
    "                                max_depth= 5)\n",
    "    \n",
    "    # Train\n",
    "    start_time_train = time.time()\n",
    "    rf.fit(X_train, y_train)\n",
    "    end_time_train = time.time()\n",
    "    \n",
    "    # Predict\n",
    "    start_time_predict = time.time()\n",
    "    preds = rf.predict(X_test)\n",
    "    end_time_predict = time.time()\n",
    "    \n",
    "    # Evaluate\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    # Save times\n",
    "    train_times.append(end_time_train - start_time_train)\n",
    "    predict_times.append(end_time_predict - start_time_predict)\n",
    "    \n",
    "    print(f\"n_estimators={n}: Accuracy={acc:.4f}, Train={train_times[-1]:.2f}s, Predict={predict_times[-1]:.2f}s\")\n",
    "\n",
    "# Summarize results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'n_estimators': n_values,\n",
    "    'accuracy': accuracies,\n",
    "    'train_time_s': train_times,\n",
    "    'predict_time_s': predict_times\n",
    "})\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqeGJ0Jsdcl2"
   },
   "source": [
    "#### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiAiRns7vPo7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import time\n",
    "# Hyperparameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [200, 300, 400, 500, 600, 800],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Randomized Search CV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,         # try 10 random combinations\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,         # prints status after each iteration\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit randomized search\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nRandomized Search finished in {end_time - start_time:.2f} seconds\")\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_rf = random_search.best_estimator_\n",
    "predictions = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2u1UehOnvBzN"
   },
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWc-7NKLvNCj"
   },
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xBmuzkKvTj2"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize SVM (RBF kernel is standard)\n",
    "svm = SVC(kernel=\"linear\", random_state=42, class_weight='balanced', probability=True)\n",
    "\n",
    "# Measure training time\n",
    "start_time_train = time.time()\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "print(\"Training finished!\")\n",
    "end_time_train = time.time()\n",
    "\n",
    "# Predictions + probabilities\n",
    "start_time_predict = time.time()\n",
    "predictions = svm.predict(X_test_scaled)\n",
    "end_time_predict = time.time()\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(f\"Linear SVM training time: {end_time_train - start_time_train:.2f} seconds\")\n",
    "print(f\"Linear SVM prediction time: {end_time_predict - start_time_predict:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICotaOhcvRPE"
   },
   "source": [
    "#### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbvU2evRvUEI"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Base SVM\n",
    "svm = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "\n",
    "# Hyperparameter distribution\n",
    "param_dist = {\n",
    "    'C': np.logspace(-2, 2, 10),           # 0.01 to 100\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 1, 5)),  # include numeric gamma values\n",
    "    'degree': [2, 3, 4, 5]                 # for 'poly' kernel\n",
    "}\n",
    "\n",
    "# Randomized Search CV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,         # 10 random combinations\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,         # prints status after each iteration\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit randomized search\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nRandomized Search finished in {end_time - start_time:.2f} seconds\")\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_svm = random_search.best_estimator_\n",
    "predictions = best_svm.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tz-m1oavEIr"
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAjGJG83vNoj"
   },
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsRPCUTKvUi5"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize KNN (default k=5)\n",
    "knn = KNeighborsClassifier(n_neighbors=69)\n",
    "\n",
    "# Measure training time\n",
    "start_time_train = time.time()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print(\"Training finished!\")\n",
    "end_time_train = time.time()\n",
    "\n",
    "# Predictions'\n",
    "start_time_predict = time.time()\n",
    "predictions = knn.predict(X_test_scaled)\n",
    "end_time_predict = time.time()\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(f\"KNN training time: {end_time_train - start_time_train:.2f} seconds\")\n",
    "print(f\"KNN prediction time: {end_time_predict - start_time_predict:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7Dgjb6RvRwJ"
   },
   "source": [
    "#### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wgxTyuNvU5m"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import time\n",
    "\n",
    "# Initialize KNN\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define hyperparameter distribution\n",
    "param_dist = {\n",
    "    'n_neighbors': range(31, 99),                  \n",
    "    'weights': ['uniform', 'distance'],           \n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']  \n",
    "}\n",
    "\n",
    "# Randomized search with verbose output\n",
    "random_search = RandomizedSearchCV(\n",
    "    knn,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2  # <-- This will print status of each iteration\n",
    ")\n",
    "\n",
    "# Fit randomized search on training data\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nRandomized Search finished in {end_time - start_time:.2f} seconds\")\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_knn = random_search.best_estimator_\n",
    "predictions = best_knn.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsQsRyikvGox"
   },
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyV-PapwvOFI"
   },
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rip5TuPNvVUF"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize CatBoost\n",
    "cb = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=0,          # turn off CatBoost's built-in output\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Measure training time\n",
    "start_time_train = time.time()\n",
    "cb.fit(X_train, y_train)\n",
    "print(\"Training finished!\")\n",
    "end_time_train = time.time()\n",
    "\n",
    "# Predictions and probabilities\n",
    "start_time_predict = time.time()\n",
    "predictions = cb.predict(X_test)\n",
    "probs = cb.predict_proba(X_test)[:, 1]\n",
    "end_time_predict = time.time()\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"CatBoost Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(f\"CatBoost training time: {end_time_train - start_time_train:.2f} seconds\")\n",
    "print(f\"CatBoost prediction time: {end_time_predict - start_time_predict:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqUyQunavSWp"
   },
   "source": [
    "#### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDFGASyVvWBt"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import time\n",
    "\n",
    "# Initialize CatBoost\n",
    "cb = CatBoostClassifier(\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=0,      # we will control output via RandomizedSearchCV\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define hyperparameter distribution\n",
    "param_dist = {\n",
    "    'iterations': [200, 500, 800],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'border_count': [32, 64, 128, 254]\n",
    "}\n",
    "\n",
    "# Randomized search with 5-fold CV and 20 random combinations\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=cb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,          # prints status after each iteration\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit randomized search on training data\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nRandomized Search finished in {end_time - start_time:.2f} seconds\")\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_cb = random_search.best_estimator_\n",
    "predictions = best_cb.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"CatBoost Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    objective='multi:softprob',  # change if multiclass: 'multi:softprob'\n",
    "    eval_metric='logloss',        # can also use 'error' or 'auc'\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Measure training time\n",
    "start_time_train = time.time()\n",
    "xgb.fit(X_train, y_train)\n",
    "end_time_train = time.time()\n",
    "print(\"Training finished!\")\n",
    "\n",
    "# Predictions and probabilities\n",
    "start_time_predict = time.time()\n",
    "predictions = xgb.predict(X_test)\n",
    "probs = xgb.predict_proba(X_test)[:, 1]  # probability for positive class\n",
    "end_time_predict = time.time()\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(f\"XGBoost training time: {end_time_train - start_time_train:.2f} seconds\")\n",
    "print(f\"XGBoost prediction time: {end_time_predict - start_time_predict:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Base XGBoost model\n",
    "xgb = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Hyperparameter distribution for Randomized Search\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 300, 500, 700],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 6, 8, 10],\n",
    "    'subsample': [0.6, 0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2, 3]\n",
    "}\n",
    "\n",
    "# Randomized Search CV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,         # try 20 random combinations\n",
    "    cv=3,              # 3-fold CV for faster tuning\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,         # prints status per iteration\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit Randomized Search\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nRandomized Search finished in {end_time - start_time:.2f} seconds\")\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_xgb = random_search.best_estimator_\n",
    "predictions = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZM8CAnNusBZ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mqrx7ZydgT3"
   },
   "outputs": [],
   "source": [
    "# First, install RAPIDS (run this in a Colab cell)\n",
    "!wget -qO- https://raw.githubusercontent.com/rapidsai/cuml/main/python/colab/rapids-colab.sh | bash\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.8/site-packages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1Wts4VXipJX",
    "outputId": "b0ca8509-76fe-4f29-c84b-240b14edc325"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "bY82DHY0dg32",
    "outputId": "f4ad1bfa-fb67-4ce8-b8c6-76790ef12006"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import cudf\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score  # or other preferred metric\n",
    "\n",
    "# Example: split your training set further into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_cu, X_val_cu, y_train_cu, y_val_cu = train_test_split(\n",
    "    X_train_cu, y_train_cu, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'max_features': [0.5, 0.7, 1.0],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Generate all parameter combinations\n",
    "param_combinations = list(itertools.product(\n",
    "    param_grid['n_estimators'],\n",
    "    param_grid['max_depth'],\n",
    "    param_grid['max_features'],\n",
    "    param_grid['min_samples_split']\n",
    "))\n",
    "\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for n_estimators, max_depth, max_features, min_samples_split in param_combinations:\n",
    "    print(f\"Testing params: n_estimators={n_estimators}, max_depth={max_depth}, max_features={max_features}, min_samples_split={min_samples_split}\")\n",
    "\n",
    "    # Instantiate model with current params\n",
    "    rf = cuRF(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        max_features=max_features,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit on training set (GPU)\n",
    "    rf.fit(X_train_cu, y_train_cu)\n",
    "\n",
    "    # Predict on validation set\n",
    "    preds_cu = rf.predict(X_val_cu)\n",
    "    preds = preds_cu.to_pandas().to_numpy()  # convert to CPU numpy\n",
    "\n",
    "    y_val = y_val_cu.to_pandas().to_numpy()\n",
    "\n",
    "    # Calculate accuracy or your preferred metric\n",
    "    score = accuracy_score(y_val, preds)\n",
    "    print(f\"Validation Accuracy: {score:.4f}\")\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'max_features': max_features,\n",
    "            'min_samples_split': min_samples_split\n",
    "        }\n",
    "        print(\"New best score found\")\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {best_params}\")\n",
    "print(f\"Best validation accuracy: {best_score:.4f}\")\n",
    "\n",
    "# After, train final model with best params on full training data\n",
    "final_rf = cuRF(**best_params, random_state=42)\n",
    "final_rf.fit(X_train_cu, y_train_cu)\n",
    "\n",
    "# Use final_rf for test predictions, evaluation, etc.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
